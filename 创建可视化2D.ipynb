{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8681 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m frame_data \u001b[39m=\u001b[39m FrameDataLoader(kitti_locations\u001b[39m=\u001b[39mkitti_locations,\n\u001b[1;32m     24\u001b[0m                          frame_number\u001b[39m=\u001b[39mimg_name)\n\u001b[1;32m     25\u001b[0m vis2d \u001b[39m=\u001b[39m Visualization2D(frame_data)\n\u001b[0;32m---> 26\u001b[0m vis2d\u001b[39m.\u001b[39;49mdraw_plot(\u001b[39m#show_lidar=True,\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m                 plot_figure\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     28\u001b[0m                 show_radar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m                 \u001b[39m# show_gt=True,\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m                 min_distance_threshold\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m                 max_distance_threshold\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     32\u001b[0m                 save_figure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/workspace/mot/whatch_delft_dataset/vod/visualization/vis_2d.py:148\u001b[0m, in \u001b[0;36mVisualization2D.draw_plot\u001b[0;34m(self, plot_figure, save_figure, show_gt, show_pred, show_lidar, show_radar, max_distance_threshold, min_distance_threshold, score_threshold)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_lidar_pcl(max_distance_threshold\u001b[39m=\u001b[39mmax_distance_threshold,\n\u001b[1;32m    145\u001b[0m                         min_distance_threshold\u001b[39m=\u001b[39mmin_distance_threshold)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m show_radar:\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplot_radar_pcl(max_distance_threshold\u001b[39m=\u001b[39;49mmax_distance_threshold,\n\u001b[1;32m    149\u001b[0m                         min_distance_threshold\u001b[39m=\u001b[39;49mmin_distance_threshold)\n\u001b[1;32m    151\u001b[0m plt\u001b[39m.\u001b[39mimshow(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_copy, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    152\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/mot/whatch_delft_dataset/vod/visualization/vis_2d.py:78\u001b[0m, in \u001b[0;36mVisualization2D.plot_radar_pcl\u001b[0;34m(self, max_distance_threshold, min_distance_threshold)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mplot_radar_pcl\u001b[39m(\u001b[39mself\u001b[39m, max_distance_threshold, min_distance_threshold):\n\u001b[1;32m     73\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mThis method plots the radar pcl on the frame. It colors the points based on distance.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m        :param max_distance_threshold: The maximum distance where points are rendered.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m        :param min_distance_threshold: The minimum distance where points are rendered.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m         uvs, points_depth \u001b[39m=\u001b[39m project_pcl_to_image(point_cloud\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_data_loader\u001b[39m.\u001b[39;49mradar_data,\n\u001b[1;32m     79\u001b[0m                                                  t_camera_pcl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_transformations\u001b[39m.\u001b[39;49mt_camera_radar,\n\u001b[1;32m     80\u001b[0m                                                  camera_projection_matrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_transformations\u001b[39m.\u001b[39;49mcamera_projection_matrix,\n\u001b[1;32m     81\u001b[0m                                                  image_shape\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_data_loader\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     83\u001b[0m         min_max_idx \u001b[39m=\u001b[39m min_max_filter(points\u001b[39m=\u001b[39mpoints_depth,\n\u001b[1;32m     84\u001b[0m                                      max_value\u001b[39m=\u001b[39mmax_distance_threshold,\n\u001b[1;32m     85\u001b[0m                                      min_value\u001b[39m=\u001b[39mmin_distance_threshold)\n\u001b[1;32m     86\u001b[0m         uvs \u001b[39m=\u001b[39m uvs[min_max_idx]\n",
      "File \u001b[0;32m/workspace/mot/whatch_delft_dataset/vod/frame/transformations.py:379\u001b[0m, in \u001b[0;36mproject_pcl_to_image\u001b[0;34m(point_cloud, t_camera_pcl, camera_projection_matrix, image_shape)\u001b[0m\n\u001b[1;32m    374\u001b[0m radar_points_camera_frame \u001b[39m=\u001b[39m homogeneous_transformation(point_homo,\n\u001b[1;32m    375\u001b[0m                                                        transform\u001b[39m=\u001b[39mt_camera_pcl)\n\u001b[1;32m    377\u001b[0m point_depth \u001b[39m=\u001b[39m radar_points_camera_frame[:, \u001b[39m2\u001b[39m]\n\u001b[0;32m--> 379\u001b[0m uvs \u001b[39m=\u001b[39m project_3d_to_2d(points\u001b[39m=\u001b[39;49mradar_points_camera_frame,\n\u001b[1;32m    380\u001b[0m                        projection_matrix\u001b[39m=\u001b[39;49mcamera_projection_matrix)\n\u001b[1;32m    382\u001b[0m filtered_idx \u001b[39m=\u001b[39m canvas_crop(points\u001b[39m=\u001b[39muvs,\n\u001b[1;32m    383\u001b[0m                            image_size\u001b[39m=\u001b[39mimage_shape,\n\u001b[1;32m    384\u001b[0m                            points_depth\u001b[39m=\u001b[39mpoint_depth)\n\u001b[1;32m    385\u001b[0m uvs \u001b[39m=\u001b[39m uvs[filtered_idx]\n",
      "File \u001b[0;32m/workspace/mot/whatch_delft_dataset/vod/frame/transformations.py:325\u001b[0m, in \u001b[0;36mproject_3d_to_2d\u001b[0;34m(points, projection_matrix)\u001b[0m\n\u001b[1;32m    323\u001b[0m uvw \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m uvw[\u001b[39m2\u001b[39m]\n\u001b[1;32m    324\u001b[0m uvs \u001b[39m=\u001b[39m uvw[:\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 325\u001b[0m uvs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(uvs)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39;49mint)\n\u001b[1;32m    327\u001b[0m \u001b[39mreturn\u001b[39;00m uvs\n",
      "File \u001b[0;32m/opt/conda/envs/delft/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from vod.configuration import KittiLocations\n",
    "from vod.frame import FrameDataLoader\n",
    "from vod.visualization import Visualization2D\n",
    "\n",
    "kitti_locations = KittiLocations(root_dir=\"/workspace/mot/whatch_delft_dataset/view_of_delft\",\n",
    "                                output_dir=\"/workspace/mot/whatch_delft_dataset/output_image\")\n",
    "\n",
    "\n",
    "\n",
    "start_indices = []\n",
    "end_indices = []\n",
    "\n",
    "with open('/workspace/mot/whatch_delft_dataset/view_of_delft/lidar/ImageSets/full.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    frame_numbers = [int(line.strip()) for line in lines]\n",
    "\n",
    "for i in tqdm(range(len(frame_numbers) - 1)):\n",
    "    img_name = f\"{i:05d}\"\n",
    "    \n",
    "    frame_data = FrameDataLoader(kitti_locations=kitti_locations,\n",
    "                             frame_number=img_name)\n",
    "    vis2d = Visualization2D(frame_data)\n",
    "    vis2d.draw_plot(#show_lidar=True,\n",
    "                    plot_figure=False,\n",
    "                    show_radar=True,\n",
    "                    # show_gt=True,\n",
    "                    min_distance_threshold=5,\n",
    "                    max_distance_threshold=20,\n",
    "                    save_figure=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vod.configuration import KittiLocations\n",
    "from vod.frame import FrameDataLoader\n",
    "\n",
    "\n",
    "kitti_locations = KittiLocations(root_dir=\"example_set\",\n",
    "                                output_dir=\"example_output\")\n",
    "\n",
    "frame_data = FrameDataLoader(kitti_locations=kitti_locations,\n",
    "                             frame_number=\"01201\")\n",
    "\n",
    "from vod.visualization import Visualization2D\n",
    "\n",
    "vis2d = Visualization2D(frame_data)\n",
    "\n",
    "vis2d.draw_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Mar  2 2023, 03:21:46) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b3c50f70a3abf17f16942c447a12d3f136c8bd8c10d51cdde5d8537891b843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
